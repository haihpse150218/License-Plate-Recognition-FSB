# frontend/app.py
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration, VideoHTMLAttributes
import cv2
import numpy as np
import requests
import av
from PIL import Image
import io
import time
import base64
import os
import uuid

# ƒê·ªãa ch·ªâ backend FastAPI (c√≥ th·ªÉ ƒë·ªïi khi deploy)
API_URL = "http://127.0.0.1:8000/ocr"
BACKEND_HOST = "http://127.0.0.1:8000"  # D√πng bi·∫øn n√†y ƒë·ªÉ x√¢y d·ª±ng URL ƒë·∫ßy ƒë·ªß

st.set_page_config(page_title="Bi·ªÉn S·ªë Xe OCR", layout="wide")
st.title("Nh·∫≠n di·ªán bi·ªÉn s·ªë xe Vi·ªát Nam")
st.markdown("Ch·ªçn tab ƒë·ªÉ upload ·∫£nh ho·∫∑c d√πng camera realtime.")

tab1, tab2 = st.tabs(["üìÅ Upload ·∫¢nh", "üé• Camera Real-time"])

# ----------------------- TAB 1: Upload ·∫¢nh -----------------------
with tab1:
    st.subheader("Upload ·∫£nh xe")
    uploaded_file = st.file_uploader("Ch·ªçn file ·∫£nh (jpg/png)", type=["jpg", "jpeg", "png"])

    if uploaded_file is not None:
        image = Image.open(uploaded_file)
        st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)

        if st.button("X·ª≠ l√Ω ·∫£nh"):
            with st.spinner("ƒêang detect v√† OCR..."):
                files = {"file": (uploaded_file.name, uploaded_file.getvalue(), uploaded_file.type)}
                response = requests.post(API_URL, files=files)

                if response.status_code == 200:
                    data = response.json()
                    if data["status"] == "success":
                        st.success("X·ª≠ l√Ω th√†nh c√¥ng!")

                        # X√¢y d·ª±ng URL ƒë·∫ßy ƒë·ªß cho ·∫£nh processed
                        processed_relative = data["processed_image_url"]
                        processed_url = f"{BACKEND_HOST}{processed_relative}"
                        processed_response = requests.get(processed_url)
                        if processed_response.status_code == 200:
                            st.image(processed_response.content, caption="·∫¢nh ƒë√£ detect & OCR", use_container_width=True)

                        st.subheader("K·∫øt qu·∫£ nh·∫≠n di·ªán")
                        for det in data["detections"]:
                            st.write(f"**Bi·ªÉn s·ªë:** {det['plate']}")
                            st.write(f"**ƒê·ªô tin c·∫≠y:** {det['confidence']:.2f}")
                            st.write(f"**V·ªã tr√≠ bbox:** {det['bbox']}")

                            if "crop_path" in det:
                                # X√¢y d·ª±ng URL ƒë·∫ßy ƒë·ªß cho crop
                                crop_relative = det["crop_path"].replace("crop_images", "/crops")
                                crop_url = f"{BACKEND_HOST}{crop_relative}"
                                crop_response = requests.get(crop_url)
                                if crop_response.status_code == 200:
                                    st.image(crop_response.content, caption=f"Crop bi·ªÉn s·ªë: {det['plate']}", width=300)
                    else:
                        st.error("L·ªói t·ª´ backend: " + str(data))
                else:
                    st.error(f"L·ªói k·∫øt n·ªëi backend: {response.status_code} - {response.text}")

# ----------------------- TAB 2: Camera Real-time -----------------------
with tab2:
    st.subheader("Camera Real-time OCR")

    # Th∆∞ m·ª•c l∆∞u ·∫£nh ch·ª•p
    captured_dir = "captured_photos"
    os.makedirs(captured_dir, exist_ok=True)

    # Kh·ªüi t·∫°o session state
    if 'captured_frame' not in st.session_state:
        st.session_state.captured_frame = None
    if 'captured_result' not in st.session_state:
        st.session_state.captured_result = None
    if 'capture_requested' not in st.session_state:
        st.session_state.capture_requested = False

    class VideoProcessor(VideoTransformerBase):
        def __init__(self):
            self.last_time = time.time()

        def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
            img = frame.to_ndarray(format="bgr24")

            # Chuy·ªÉn frame th√†nh bytes
            _, buffer = cv2.imencode('.jpg', img)
            image_bytes = buffer.tobytes()

            try:
                files = {"file": ("frame.jpg", image_bytes, "image/jpeg")}
                response = requests.post(API_URL, files=files, timeout=3)

                if response.status_code == 200:
                    data = response.json()
                    if data["status"] == "success" and data["detections"]:
                        for det in data["detections"]:
                            plate = det["plate"]
                            conf = det["confidence"]
                            bbox = det["bbox"]
                            x1, y1, x2, y2 = bbox

                            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                            cv2.putText(img, f"{plate} ({conf:.2f})", (x1, y1 - 10),
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)

                        # L∆∞u frame n·∫øu n√∫t ch·ª•p ƒë∆∞·ª£c nh·∫•n
                        if st.session_state.capture_requested:
                            st.session_state.captured_frame = img.copy()
                            st.session_state.captured_result = data
                            st.session_state.capture_requested = False

            except Exception as e:
                cv2.putText(img, f"Error: {str(e)}", (10, 30),
                            cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)

            # Gi·ªõi h·∫°n FPS
            current_time = time.time()
            if current_time - self.last_time < 0.1:
                time.sleep(0.1 - (current_time - self.last_time))
            self.last_time = current_time

            return av.VideoFrame.from_ndarray(img, format="bgr24")

    RTC_CONFIGURATION = RTCConfiguration({
        "iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]
    })

    # Streamer
    ctx = webrtc_streamer(
        key="real-time-ocr",
        video_transformer_factory=VideoProcessor,
        rtc_configuration=RTC_CONFIGURATION,
        media_stream_constraints={"video": True, "audio": False},
        video_html_attrs=VideoHTMLAttributes(muted=True, volume=0)
    )

    # N√∫t ch·ª•p ·∫£nh
    if st.button("üì∏ Ch·ª•p ·∫£nh"):
        st.session_state.capture_requested = True
        st.success("ƒê√£ ch·ª•p! ƒêang x·ª≠ l√Ω...")

    # Hi·ªÉn th·ªã ·∫£nh v·ª´a ch·ª•p (n·∫øu c√≥)
    if st.session_state.captured_frame is not None:
        st.subheader("·∫¢nh v·ª´a ch·ª•p")
        captured_rgb = cv2.cvtColor(st.session_state.captured_frame, cv2.COLOR_BGR2RGB)
        st.image(captured_rgb, channels="RGB", use_container_width=True)

        # Hi·ªÉn th·ªã k·∫øt qu·∫£ OCR
        if st.session_state.captured_result and st.session_state.captured_result["detections"]:
            st.subheader("K·∫øt qu·∫£ nh·∫≠n di·ªán")
            for det in st.session_state.captured_result["detections"]:
                st.write(f"**Bi·ªÉn s·ªë:** {det['plate']}")
                st.write(f"**ƒê·ªô tin c·∫≠y:** {det['confidence']:.2f}")

            # N√∫t t·∫£i ·∫£nh
            _, buffer = cv2.imencode('.jpg', st.session_state.captured_frame)
            b64 = base64.b64encode(buffer).decode()
            href = f'<a href="data:image/jpeg;base64,{b64}" download="captured_plate.jpg">T·∫£i ·∫£nh v·ªÅ</a>'
            st.markdown(href, unsafe_allow_html=True)

        # L∆∞u ·∫£nh v√†o th∆∞ m·ª•c
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        save_path = os.path.join(captured_dir, f"capture_{timestamp}.jpg")
        cv2.imwrite(save_path, st.session_state.captured_frame)
        st.info(f"·∫¢nh ƒë√£ ƒë∆∞·ª£c l∆∞u t·∫°i: {save_path}")

        # N√∫t x√≥a ·∫£nh ch·ª•p
        if st.button("X√≥a ·∫£nh v·ª´a ch·ª•p"):
            st.session_state.captured_frame = None
            st.session_state.captured_result = None
            st.rerun()

    st.info("N·∫øu camera kh√¥ng m·ªü: Cho ph√©p quy·ªÅn truy c·∫≠p webcam trong tr√¨nh duy·ªát. Backend ph·∫£i ch·∫°y t·∫°i port 8000.")