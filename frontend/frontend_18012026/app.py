# frontend/app.py
# Streamlit frontend cho License Plate Recognition
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, RTCConfiguration, VideoHTMLAttributes
import cv2
import numpy as np
import requests
import av
from PIL import Image
import io
import time
import base64
import os
from typing import Optional, Dict, List, Tuple
from dataclasses import dataclass

# ======================== CONFIGURATION ========================
API_URL = "http://127.0.0.1:8000/ocr"
BACKEND_HOST = "http://127.0.0.1:8000"
CAPTURED_DIR = "captured_photos"

# Cáº¥u hÃ¬nh tá»‘i Æ°u cho performance
DEFAULT_PROCESS_INTERVAL = 5.0  # GiÃ¢y giá»¯a cÃ¡c request
DEFAULT_SKIP_FRAMES = 10  # Sá»‘ frame bá» qua
DEFAULT_IMAGE_WIDTH = 640  # Chiá»u rá»™ng áº£nh tá»‘i Ä‘a
DEFAULT_JPEG_QUALITY = 70  # Cháº¥t lÆ°á»£ng JPEG (0-100)
API_TIMEOUT = 10  # Timeout cho API requests (giÃ¢y)
HEALTH_CHECK_CACHE_TTL = 5  # Cache health check trong 5 giÃ¢y

# ======================== DATA CLASSES ========================
@dataclass
class Detection:
    """Káº¿t quáº£ nháº­n diá»‡n má»™t biá»ƒn sá»‘"""
    plate: str
    confidence: float
    bbox: List[int]

@dataclass
class OCRResult:
    """Káº¿t quáº£ OCR tá»« API"""
    status: str
    detections: List[Detection]
    processed_image_url: Optional[str] = None
    plate_type: Optional[str] = None
    error_message: Optional[str] = None

def init_session_state():

    defaults = {
        'input_image': None,
        'show_camera_input': False,
        'captured_frame': None,
        'captured_result': None,
        'capture_requested': False,
        'last_detection': None,
        'frame_count': 0,
        'api_error_count': 0,
        'process_interval': DEFAULT_PROCESS_INTERVAL,
        'skip_frames': DEFAULT_SKIP_FRAMES,
        'health_check_time': 0,
        'health_check_result': None,
    }
    
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

@st.cache_data(ttl=HEALTH_CHECK_CACHE_TTL)
def check_api_health_cached() -> Tuple[bool, str]:
    """Check API health vá»›i cache Ä‘á»ƒ giáº£m sá»‘ láº§n request"""
    try:
        response = requests.get(f"{BACKEND_HOST}/health", timeout=API_TIMEOUT)
        if response.status_code == 200:
            return True, "Backend API Ä‘ang cháº¡y"
        return False, f"Backend tráº£ vá» mÃ£ lá»—i: {response.status_code}"
    except requests.exceptions.ConnectionError:
        return False, "KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c Backend API"
    except requests.exceptions.Timeout:
        return False, "Timeout khi kiá»ƒm tra API"
    except Exception as e:
        return False, f"Lá»—i: {str(e)[:50]}"

def check_api_health() -> Tuple[bool, str]:

    current_time = time.time()

    if (current_time - st.session_state.health_check_time) > HEALTH_CHECK_CACHE_TTL:
        st.session_state.health_check_result = check_api_health_cached()
        st.session_state.health_check_time = current_time
    return st.session_state.health_check_result

def parse_ocr_response(data: Dict) -> OCRResult:
    """Parse API response thÃ nh OCRResult object"""
    detections = []
    if data.get("detections"):
        for det in data["detections"]:
            detections.append(Detection(
                plate=det.get("plate", "Unknown"),
                confidence=det.get("confidence", 0.0),
                bbox=det.get("bbox", [])
            ))
    
    return OCRResult(
        status=data.get("status", "error"),
        detections=detections,
        processed_image_url=data.get("processed_image_url"),
        plate_type=data.get("type"),
        error_message=data.get("message")
    )

def process_image_ocr(image_bytes: bytes, filename: str = "image.jpg") -> Optional[OCRResult]:
    """Gá»­i áº£nh Ä‘áº¿n OCR API vÃ  tráº£ vá» káº¿t quáº£"""
    try:
        files = {"file": (filename, image_bytes, "image/jpeg")}
        response = requests.post(API_URL, files=files, timeout=API_TIMEOUT)
        
        if response.status_code == 200:
            return parse_ocr_response(response.json())
        else:
            return OCRResult(
                status="error",
                detections=[],
                error_message=f"API error: {response.status_code}"
            )
    except requests.exceptions.Timeout:
        return OCRResult(
            status="error",
            detections=[],
            error_message="Timeout - API khÃ´ng pháº£n há»“i ká»‹p thá»i"
        )
    except requests.exceptions.ConnectionError:
        return OCRResult(
            status="error",
            detections=[],
            error_message="KhÃ´ng káº¿t ná»‘i Ä‘Æ°á»£c vá»›i API"
        )
    except Exception as e:
        return OCRResult(
            status="error",
            detections=[],
            error_message=str(e)
        )

def display_processed_image(processed_image_url: str):
    """Hiá»ƒn thá»‹ áº£nh Ä‘Ã£ Ä‘Æ°á»£c xá»­ lÃ½ tá»« API"""
    if not processed_image_url:
        return
        
    if processed_image_url.startswith("data:image"):
        base64_data = processed_image_url.split(",")[1]
        image_bytes = base64.b64decode(base64_data)
        st.image(image_bytes, caption="áº¢nh Ä‘Ã£ detect & OCR", use_container_width=True)
    elif processed_image_url.startswith("http"):
        try:
            img_response = requests.get(processed_image_url, timeout=5)
            if img_response.status_code == 200:
                st.image(img_response.content, caption="áº¢nh Ä‘Ã£ detect & OCR", use_container_width=True)
        except Exception:
            st.warning("KhÃ´ng thá»ƒ táº£i áº£nh tá»« URL")

def display_ocr_result(result: OCRResult):
    """Hiá»ƒn thá»‹ káº¿t quáº£ OCR trong Streamlit"""
    if result.status == "success" and result.detections:
        st.success(f"âœ… Xá»­ lÃ½ thÃ nh cÃ´ng! TÃ¬m tháº¥y {len(result.detections)} biá»ƒn sá»‘")
        
        # Hiá»ƒn thá»‹ áº£nh Ä‘Ã£ xá»­ lÃ½
        if result.processed_image_url:
            display_processed_image(result.processed_image_url)
        
        # Hiá»ƒn thá»‹ chi tiáº¿t tá»«ng biá»ƒn sá»‘
        st.subheader("Káº¿t quáº£ nháº­n diá»‡n")
        for idx, det in enumerate(result.detections, 1):
            with st.expander(f"Biá»ƒn sá»‘ #{idx}: {det.plate}", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("Biá»ƒn sá»‘", det.plate)
                    st.metric("Äá»™ tin cáº­y", f"{det.confidence:.2%}")
                with col2:
                    if result.plate_type:
                        st.metric("Loáº¡i", result.plate_type)
                    st.write(f"**BBox:** {det.bbox}")
    
    elif result.status == "no_detection":
        st.warning("âš ï¸ KhÃ´ng tÃ¬m tháº¥y biá»ƒn sá»‘ nÃ o trong áº£nh")
    else:
        st.error(f"âŒ Lá»—i: {result.error_message or 'Xá»­ lÃ½ tháº¥t báº¡i'}")

# ======================== PAGE CONFIG ========================
st.set_page_config(
    page_title="Biá»ƒn Sá»‘ Xe OCR",
    page_icon="ğŸš—",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Initialize
init_session_state()
os.makedirs(CAPTURED_DIR, exist_ok=True)

# Header
st.title("ğŸš— Nháº­n diá»‡n biá»ƒn sá»‘ xe Viá»‡t Nam")
st.markdown("Chá»n tab Ä‘á»ƒ upload áº£nh hoáº·c dÃ¹ng camera realtime.")

# API Health Check
api_healthy, api_message = check_api_health()
if api_healthy:
    st.success(f"âœ… {api_message}")
else:
    st.error(f"âŒ {api_message}")


tab1, tab2 = st.tabs(["ğŸ“ Upload áº¢nh", "ğŸ¥ Camera Real-time"])

with tab1:
    st.subheader("Upload hoáº·c chá»¥p áº£nh xe")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        uploaded_file = st.file_uploader(
            "ğŸ“ Chá»n áº£nh tá»« mÃ¡y tÃ­nh",
            type=["jpg", "jpeg", "png"],
            help="Há»— trá»£ Ä‘á»‹nh dáº¡ng JPG, JPEG, PNG"
        )
        
        if uploaded_file:
            st.session_state.input_image = uploaded_file.getvalue()
            st.session_state.show_camera_input = False
    
    with col2:
        if st.button("ğŸ“¸ Chá»¥p áº£nh tá»« camera", use_container_width=True):
            st.session_state.show_camera_input = not st.session_state.show_camera_input
            st.rerun()
    
    # Camera input
    if st.session_state.show_camera_input:
        camera_photo = st.camera_input("Chá»¥p áº£nh")
        if camera_photo:
            st.session_state.input_image = camera_photo.getvalue()
            st.session_state.show_camera_input = False
            st.rerun()
    
    # Display input image
    if st.session_state.input_image:
        st.markdown("### áº¢nh Ä‘áº§u vÃ o")
        try:
            image = Image.open(io.BytesIO(st.session_state.input_image))
            st.image(image, use_container_width=True)
        except Exception as e:
            st.error(f"Lá»—i Ä‘á»c áº£nh: {str(e)}")
            st.session_state.input_image = None
        
        # Action buttons
        col_btn1, col_btn2 = st.columns(2)
        
        with col_btn1:
            if st.button("ğŸš€ Xá»­ lÃ½ áº£nh", type="primary", use_container_width=True):
                with st.spinner("Äang xá»­ lÃ½..."):
                    result = process_image_ocr(st.session_state.input_image)
                    if result:
                        display_ocr_result(result)
        
        with col_btn2:
            if st.button("âŒ XÃ³a áº£nh", use_container_width=True):
                st.session_state.input_image = None
                st.session_state.show_camera_input = False
                st.rerun()
    else:
        st.info("ğŸ“Œ ChÆ°a cÃ³ áº£nh. Vui lÃ²ng upload hoáº·c chá»¥p áº£nh.")

with tab2:
    st.subheader("Camera Real-time OCR")
    
    # Configuration sliders
    col_config1, col_config2 = st.columns(2)
    with col_config1:
        process_interval = st.slider(
            "Táº§n suáº¥t xá»­ lÃ½ (giÃ¢y)",
            1.0, 10.0, DEFAULT_PROCESS_INTERVAL, 0.5,
            help="Khoáº£ng thá»i gian giá»¯a cÃ¡c láº§n gá»­i request (Máº·c Ä‘á»‹nh: 5 giÃ¢y - Tá»‘i Æ°u)"
        )
        st.session_state.process_interval = process_interval
    
    with col_config2:
        skip_frames = st.slider(
            "Bá» qua frame",
            5, 20, DEFAULT_SKIP_FRAMES, 1,
            help="Chá»‰ xá»­ lÃ½ má»—i N frame (Máº·c Ä‘á»‹nh: 10 - Tá»‘i Æ°u)"
        )
        st.session_state.skip_frames = skip_frames
    
    # Video Processor Class - Tá»‘i Æ°u Ä‘á»ƒ giáº£m lag
    class VideoProcessor(VideoTransformerBase):
        def __init__(self):
            self.last_time = time.time()
            self.frame_counter = 0
            self.last_detection_time = 0
            self.current_detections = []
            # Cache config Ä‘á»ƒ giáº£m truy cáº­p session state
            self.skip_frames = DEFAULT_SKIP_FRAMES
            self.process_interval = DEFAULT_PROCESS_INTERVAL
        
        def update_config(self):
            """Cáº­p nháº­t config tá»« session state (gá»i Ã­t thÆ°á»ng xuyÃªn)"""
            self.skip_frames = st.session_state.get("skip_frames", DEFAULT_SKIP_FRAMES)
            self.process_interval = st.session_state.get("process_interval", DEFAULT_PROCESS_INTERVAL)
        
        def draw_detections(self, img, detections):
            """Váº½ bounding boxes vÃ  labels lÃªn áº£nh"""
            for x1, y1, x2, y2, plate, conf in detections:
                color = (0, 255, 0) if plate != "Unknown" else (0, 0, 255)
                cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
                
                label = f"{plate} ({conf:.2f})"
                if len(label) > 30:
                    label = label[:30] + "..."
                
                # Background cho text Ä‘á»ƒ dá»… Ä‘á»c
                (text_width, text_height), _ = cv2.getTextSize(
                    label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2
                )
                cv2.rectangle(
                    img, (x1, y1 - text_height - 10),
                    (x1 + text_width, y1), color, -1
                )
                cv2.putText(
                    img, label, (x1, y1 - 5),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2
                )
        
        def recv(self, frame: av.VideoFrame) -> av.VideoFrame:
            """Xá»­ lÃ½ tá»«ng frame tá»« camera"""
            img = frame.to_ndarray(format="bgr24")
            current_time = time.time()
            self.frame_counter += 1
            
            # Cáº­p nháº­t frame count (chá»‰ má»—i 10 frame Ä‘á»ƒ giáº£m overhead)
            if self.frame_counter % 10 == 0:
                st.session_state.frame_count = self.frame_counter
                # Cáº­p nháº­t config má»—i 10 frame
                self.update_config()
            
            # Bá» qua frame theo skip_frames
            if self.frame_counter % self.skip_frames != 0:
                if self.current_detections:
                    self.draw_detections(img, self.current_detections)
                return av.VideoFrame.from_ndarray(img, format="bgr24")
            
            # Kiá»ƒm tra interval giá»¯a cÃ¡c request
            if current_time - self.last_time < self.process_interval:
                if self.current_detections:
                    self.draw_detections(img, self.current_detections)
                return av.VideoFrame.from_ndarray(img, format="bgr24")
            
            # Xá»­ lÃ½ frame - gá»­i Ä‘áº¿n API
            try:
                # Resize áº£nh Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c
                height, width = img.shape[:2]
                scale = 1.0
                if width > DEFAULT_IMAGE_WIDTH:
                    scale = DEFAULT_IMAGE_WIDTH / width
                    new_size = (DEFAULT_IMAGE_WIDTH, int(height * scale))
                    img_resized = cv2.resize(img, new_size, interpolation=cv2.INTER_AREA)
                else:
                    img_resized = img
                
                # Encode thÃ nh JPEG vá»›i cháº¥t lÆ°á»£ng tá»‘i Æ°u
                encode_params = [cv2.IMWRITE_JPEG_QUALITY, DEFAULT_JPEG_QUALITY]
                _, buffer = cv2.imencode('.jpg', img_resized, encode_params)
                
                # Gá»­i Ä‘áº¿n API
                files = {"file": ("frame.jpg", buffer.tobytes(), "image/jpeg")}
                response = requests.post(API_URL, files=files, timeout=API_TIMEOUT)
                
                if response.status_code == 200:
                    data = response.json()
                    st.session_state.api_error_count = 0
                    
                    if data.get("status") == "success" and data.get("detections"):
                        self.current_detections = []
                        
                        for det in data["detections"]:
                            bbox = det.get("bbox", [])
                            if len(bbox) >= 4:
                                # Scale láº¡i tá»a Ä‘á»™ bbox vá» kÃ­ch thÆ°á»›c gá»‘c
                                x1, y1, x2, y2 = [int(c / scale) for c in bbox[:4]]
                                
                                self.current_detections.append((
                                    x1, y1, x2, y2,
                                    det.get("plate", "Unknown"),
                                    det.get("confidence", 0.0)
                                ))
                        
                        self.last_detection_time = current_time
                        st.session_state.last_detection = data
                    else:
                        # XÃ³a detection cÅ© sau 2 giÃ¢y náº¿u khÃ´ng cÃ³ detection má»›i
                        if current_time - self.last_detection_time > 2.0:
                            self.current_detections = []
                    
                    # LÆ°u frame náº¿u Ä‘Æ°á»£c yÃªu cáº§u chá»¥p
                    if st.session_state.capture_requested:
                        st.session_state.captured_frame = img.copy()
                        st.session_state.captured_result = data
                        st.session_state.capture_requested = False
                
                else:
                    st.session_state.api_error_count += 1
                    
            except requests.exceptions.Timeout:
                st.session_state.api_error_count += 1
            except requests.exceptions.ConnectionError:
                st.session_state.api_error_count += 1
            except Exception:
                st.session_state.api_error_count += 1
            
            self.last_time = current_time
            
            # Váº½ detections lÃªn frame
            if self.current_detections:
                self.draw_detections(img, self.current_detections)
            
            return av.VideoFrame.from_ndarray(img, format="bgr24")
    
    # Hiá»ƒn thá»‹ tráº¡ng thÃ¡i
    col_stat1, col_stat2, col_stat3 = st.columns(3)
    with col_stat1:
        st.metric("Frame Ä‘Ã£ xá»­ lÃ½", st.session_state.frame_count)
    with col_stat2:
        det_count = 0
        if st.session_state.last_detection:
            det_count = len(st.session_state.last_detection.get("detections", []))
        st.metric("Biá»ƒn sá»‘ hiá»‡n táº¡i", det_count)
    with col_stat3:
        if st.session_state.api_error_count > 0:
            st.error(f"âš ï¸ Lá»—i: {st.session_state.api_error_count}")
        else:
            st.success("âœ… API OK")
    
    # WebRTC Configuration
    RTC_CONFIG = RTCConfiguration({
        "iceServers": [
            {"urls": ["stun:stun.l.google.com:19302"]},
            {"urls": ["stun:stun1.l.google.com:19302"]}
        ]
    })
    
    # WebRTC Streamer
    ctx = webrtc_streamer(
        key="real-time-ocr",
        video_transformer_factory=VideoProcessor,
        rtc_configuration=RTC_CONFIG,
        media_stream_constraints={
            "video": {
                "width": {"ideal": 1280},
                "height": {"ideal": 720},
                "facingMode": "user"
            },
            "audio": False
        },
        video_html_attrs=VideoHTMLAttributes(
            autoplay=True,
            controls=True,
            muted=True,
            style={"width": "100%"}
        ),
        async_processing=True
    )
    
    # Camera status vÃ  controls
    if ctx.state.playing:
        st.success("âœ… Camera Ä‘ang cháº¡y")
        
        col_act1, col_act2 = st.columns(2)
        with col_act1:
            if st.button("ğŸ“¸ Chá»¥p áº£nh", use_container_width=True, type="primary"):
                st.session_state.capture_requested = True
                st.success("ÄÃ£ yÃªu cáº§u chá»¥p áº£nh!")
        with col_act2:
            if st.button("ğŸ”„ Reset", use_container_width=True):
                st.session_state.captured_frame = None
                st.session_state.captured_result = None
                st.session_state.frame_count = 0
                st.session_state.api_error_count = 0
                st.rerun()
    else:
        st.info("â¸ï¸ Nháº¥n START Ä‘á»ƒ báº¯t Ä‘áº§u camera")
    
    # Hiá»ƒn thá»‹ áº£nh vá»«a chá»¥p
    if st.session_state.captured_frame is not None:
        st.divider()
        st.subheader("ğŸ“¸ áº¢nh vá»«a chá»¥p")
        
        captured_rgb = cv2.cvtColor(st.session_state.captured_frame, cv2.COLOR_BGR2RGB)
        st.image(captured_rgb, use_container_width=True)
        
        if st.session_state.captured_result:
            result = parse_ocr_response(st.session_state.captured_result)
            display_ocr_result(result)
            
            # NÃºt táº£i áº£nh
            _, buffer = cv2.imencode('.jpg', st.session_state.captured_frame)
            timestamp = time.strftime("%Y%m%d_%H%M%S")
            
            st.download_button(
                label="ğŸ“¥ Táº£i áº£nh vá»",
                data=buffer.tobytes(),
                file_name=f"plate_{timestamp}.jpg",
                mime="image/jpeg",
                use_container_width=True
            )
    
    # HÆ°á»›ng dáº«n sá»­ dá»¥ng
    with st.expander("â„¹ï¸ HÆ°á»›ng dáº«n sá»­ dá»¥ng"):
        st.markdown("""
        ### ğŸ¯ CÃ¡ch sá»­ dá»¥ng:
        1. Nháº¥n **START** trÃªn video player
        2. Cho phÃ©p quyá»n truy cáº­p webcam
        3. Äiá»u chá»‰nh táº§n suáº¥t xá»­ lÃ½ náº¿u cáº§n (máº·c Ä‘á»‹nh Ä‘Ã£ tá»‘i Æ°u)
        4. Nháº¥n **Chá»¥p áº£nh** Ä‘á»ƒ lÆ°u káº¿t quáº£
        
        ### âš¡ Cáº¥u hÃ¬nh tá»‘i Æ°u (Ä‘Ã£ Ã¡p dá»¥ng):
        - **Táº§n suáº¥t xá»­ lÃ½**: 5 giÃ¢y/láº§n (giáº£m táº£i API, tiáº¿t kiá»‡m bÄƒng thÃ´ng)
        - **Bá» qua frame**: 10 frame (giáº£m lag, tÄƒng hiá»‡u suáº¥t)
        - **KÃ­ch thÆ°á»›c áº£nh**: Tá»± Ä‘á»™ng resize xuá»‘ng 640px
        - **Cháº¥t lÆ°á»£ng JPEG**: 70% (cÃ¢n báº±ng cháº¥t lÆ°á»£ng vÃ  kÃ­ch thÆ°á»›c)
        - **Timeout**: 10 giÃ¢y (Ä‘á»§ thá»i gian cho API xá»­ lÃ½)
        
        ### ğŸ”§ Kháº¯c phá»¥c sá»± cá»‘:
        - **KhÃ´ng tháº¥y video**: Kiá»ƒm tra quyá»n webcam, thá»­ refresh (F5)
        - **Váº«n lag**: TÄƒng táº§n suáº¥t lÃªn 7-10 giÃ¢y, tÄƒng bá» qua frame lÃªn 15-20
        - **Lá»—i API**: Äáº£m báº£o backend Ä‘ang cháº¡y táº¡i `http://127.0.0.1:8000`
        - **Video Ä‘en**: Kiá»ƒm tra káº¿t ná»‘i webcam, thá»­ táº¯t báº­t láº¡i
        
        ### ğŸ’¡ Tips:
        - Cáº¥u hÃ¬nh máº·c Ä‘á»‹nh (5s + 10 frames) cho káº¿t quáº£ tá»‘t nháº¥t
        - Bounding box sáº½ hiá»ƒn thá»‹ liÃªn tá»¥c khi phÃ¡t hiá»‡n biá»ƒn sá»‘
        - Äáº£m báº£o Ã¡nh sÃ¡ng Ä‘á»§ vÃ  biá»ƒn sá»‘ rÃµ rÃ ng trong khung hÃ¬nh
        - Giá»¯ xe/biá»ƒn sá»‘ tÆ°Æ¡ng Ä‘á»‘i tÄ©nh khi chá»¥p Ä‘á»ƒ Ä‘á»™ chÃ­nh xÃ¡c cao
        
        ### ğŸ“Š Hiá»‡u suáº¥t:
        - **CPU**: Tháº¥p (~10-20%)
        - **RAM**: ~200-300 MB
        - **Network**: ~1-2 MB má»—i 5 giÃ¢y
        - **Äá»™ trá»…**: < 100ms (render video)
        """)
